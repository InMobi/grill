~~~
~~ #%L
~~ Lens
~~ %%
~~ Copyright (C) 2014 Inmobi
~~ %%
~~ Licensed under the Apache License, Version 2.0 (the "License");
~~ you may not use this file except in compliance with the License.
~~ You may obtain a copy of the License at
~~ 
~~      http://www.apache.org/licenses/LICENSE-2.0
~~ 
~~ Unless required by applicable law or agreed to in writing, software
~~ distributed under the License is distributed on an "AS IS" BASIS,
~~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
~~ See the License for the specific language governing permissions and
~~ limitations under the License.
~~ #L%
~~~
Lens session configuration

===

*--+--+---+--+
|<<No.>>|<<Property Name>>|<<Default Value>>|<<Description>>|
*--+--+---+--+
|1|cube.query.fail.if.data.partial|true|Whether to fail the query of data is partial|
*--+--+---+--+
|2|cube.query.promote.select.togroupby|true|Tells whether to promote select expressions which is not inside any aggregate, to be promoted to groupby clauses, if they are already not part of groupby clauses. To enable automatic promotion, this value should be true.|
*--+--+---+--+
|3|grill.add.insert.overwrite|true|Prefix query with insert overwrite clause if the query is persistent. User can disable if user gave the clause himself. |
*--+--+---+--+
|4|grill.aux.jars| |List of comma separated jar paths, which will added to the session|
*--+--+---+--+
|5|grill.persistent.resultset|false|Whether to enable persistent resultset for queries. When enabled, server will fetch results from driver, custom format them if any and store in a configured location. The file name of query output is queryhandle-id, with configured extensions|
*--+--+---+--+
|6|grill.persistent.resultset.indriver|true|Whether the result should be persisted by driver. Currently only HiveDriver persists the results in a HDFS location.|
*--+--+---+--+
|7|grill.query.hdfs.output.path|hdfsout|The directory under the parent result directory, in which HiveDriver will persist the results, if persisting by driver is enabled. This directory should exist and should have world writable permissions sothat all users will be able put query outputs here.|
*--+--+---+--+
|8|grill.query.output.charset.encoding|UTF-8|The charset encoding for formatting query result. It supports all the encodings supported by java.io.OutputStreamWriter.|
*--+--+---+--+
|9|grill.query.output.compression.codec|org.apache.hadoop.io.compress.GzipCodec|The codec used to compress the query output, if compression is enabled|
*--+--+---+--+
|10|grill.query.output.enable.compression|false|Whether to compress the query result output|
*--+--+---+--+
|11|grill.query.output.file.extn|.csv|The extension name for the persisted query output file. If file is compressed, the extension from compression codec will be appended to this extension.|
*--+--+---+--+
|12|grill.query.output.footer| |The value of custom footer that should be written, if any. This footer will be added in formatting driver persisted results.|
*--+--+---+--+
|13|grill.query.output.formatter| |The query result output formatter for the query. If no value is specified, then org.apache.lens.lib.query.FileSerdeFormatter will be used to format in-memory result sets, org.apache.lens.lib.query.FilePersistentFormatter will be used to format driver persisted result sets.|
*--+--+---+--+
|14|grill.query.output.header| |The value of custom header that should be written, if any. If no value column names will be used as header.|
*--+--+---+--+
|15|grill.query.output.write.footer|false|Whether to write footer as part of query result. When enabled, total number of rows will be written as part of header.|
*--+--+---+--+
|16|grill.query.output.write.header|false|Whether to write header as part of query result formatting. When enabled the user given header will be added in case of driver persisted results, and column names chosen will be added as header for in-memory results. |
*--+--+---+--+
|17|grill.query.result.email.cc| |When query ends, the result/failure reason will be sent to  the user via email. The mail would be cc'ed to the addresses provided  in this field.|
*--+--+---+--+
|18|grill.query.result.fs.read.url| |Http read URL for FileSystem on which result is present, if available. For example webhdfs as http read url should http://host:port/webhdfs/v1. Currently we support only webhdfs url as the http url for HDFS file system|
*--+--+---+--+
|19|grill.query.result.size.format.threshold|10737418240|The maximum allowed size of the query result. If exceeds, no server side formatting would be done.|
*--+--+---+--+
|20|grill.query.result.split.multiple|false|Whether to split the result into multiple files. If enabled, each file will be restricted to max rows configured. All the files will be available as zip.|
*--+--+---+--+
|21|grill.query.result.split.multiple.maxrows|100000|The maximum number of rows allowed in each file, when splitting the result into multiple files is enabled.|
*--+--+---+--+
|22|grill.result.output.dir.format| |The format of the output if result is persisted in hdfs. The format should be expressed in HQL.|
*--+--+---+--+
|23|grill.result.output.serde|org.apache.lens.lib.query.CSVSerde|The default serde class name that should be used by  org.apache.lens.lib.query.FileSerdeFormatter for formatting the output  |
*--+--+---+--+
|24|grill.result.parent.dir|/tmp/grillreports|The directory for storing persisted result of query. This  directory should exist and should have writable permissions by grill server|
*--+--+---+--+
|25|grill.session.cluster.user| |Session level config which will determine which cluster user will access hdfs|
*--+--+---+--+
|26|grill.session.loggedin.user| |The username used to log in to grill. e.g. LDAP user|
*--+--+---+--+
|27|grill.whether.mail.notify|false|When a query ends, whether to notify the submitter by mail or not.|
*--+--+---+--+
|28|hive.cube.disable.aggregate.resolver|false|Tells whether to disable automatic resolution of aggregations for measures in a cube. To enable automatic resolution, this value should be false.|
*--+--+---+--+
|29|hive.cube.disable.auto.join|false|Tells whether to disable automatic resolution of join conditions between tables involved. To enable automatic resolution, this value should be false.|
*--+--+---+--+
|30|hive.metastore.batch.retrieve.max|100|Maximum number of objects (tables/partitions) can be retrieved from metastore in one batch. The higher the number, the less the number of round trips is needed to the Hive metastore server, but it may also cause higher memory requirement at the client side.|
*--+--+---+--+
|31|hive.metastore.batch.retrieve.table.partition.max|500|Maximum number of table partitions that metastore internally retrieves in one batch.|
*--+--+---+--+
|32|hive.metastore.client.connect.retry.delay|1|Number of seconds for the client to wait between consecutive connection attempts|
*--+--+---+--+
|33|hive.metastore.client.socket.timeout|20|MetaStore Client socket timeout in seconds|
*--+--+---+--+
|34|hive.metastore.connect.retries|5|Number of retries while opening a connection to metastore|
*--+--+---+--+
|35|hive.metastore.failure.retries|3|Number of call retries when Hive Metastore calls fail with Thrift errros|
*--+--+---+--+
|36|hive.metastore.uris| |The hive metastore server URI that the grill server is talking to|
*--+--+---+--+
The configuration parameters and their default values
